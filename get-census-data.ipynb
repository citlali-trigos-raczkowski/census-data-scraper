{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c89e0281-339f-4f1a-9421-e0b9d3515ffb",
   "metadata": {},
   "source": [
    "# Get Census Data\n",
    "\n",
    "In this file, we go through the below steps 1-3 in order to create a single csv file titled `cc-2003-2020-all-data.csv` covering years 2003 - 2020.\n",
    "\n",
    "## Steps\n",
    "### Step 1: Get the data from census.gov \n",
    "### Step 2a: Prepare data for years 2010-2010\n",
    "### Step 2b: Prepare data for years 2003-2009\n",
    "### Step 3: Merge the files  \n",
    "\n",
    "Details for each step are included below with the code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3b287-9b0a-493e-b657-5b856e88e7ee",
   "metadata": {},
   "source": [
    "### Step 1: Get the data from census.gov\n",
    "\n",
    "There are many folders describing different groups of years. There will be two processes here, one for 2003-2009 and one for 2010-2020. These files download as csv files.\n",
    " \n",
    "Go to this link: [https://www2.census.gov/programs-surveys/popest/datasets/](https://www2.census.gov/programs-surveys/popest/datasets/).\n",
    "\n",
    "1. For step 2, download the data for years 2010-2020 -- this will be a single file. In the above link, download the file `CC-EST2020-ALLDATA6.csv` located under 2010-2020>>counties>>asrh. Save it under folder `data`.\n",
    "2. For step 3, download the data for years 2003-2009 -- this will be multiple files. The 2003-2009 data is structured differently, in that we have to download a file for each state and aggregate them. Here you will need to go to the folder titled 2000-2009>>counties>>asrh in the link above.\n",
    "For each of the following numbers (correlating to state IDS): 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, we download the file `cc-est2009-alldata-#.csv`. Save these under folder `data/`\n",
    "\n",
    "The structure of your project should look like this:\n",
    "\n",
    "- parent_folder/\n",
    "    - get-census-data.ipynb\n",
    "    - data/\n",
    "        -  CC-EST2020-ALLDATA6.csv\n",
    "        -  cc-est2009-alldate-1.csv\n",
    "        -  ...\n",
    "        -  cc-est2009-alldate-56.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad784270-7731-4c6c-94e6-f752b1e2373c",
   "metadata": {},
   "source": [
    "The below code will go to the URL and download all the necessary files listed above into the folder data/ that is alongside this folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ac0bc7-358b-4d53-afba-20ce18168901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we check if there are folders for data and clean. \n",
    "# if there are not, we create them \n",
    "import os\n",
    "import glob\n",
    "    \n",
    "def ensure_path_exists(path, delete_folder_contents=False):\n",
    "    \"\"\"Makes path if it doesn't exist. If it does exist, it\n",
    "    deletes the contents of the path if delete_folder_contents set to True\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs('data/')\n",
    "    elif delete_folder_contents:\n",
    "        files = glob.glob(path+'/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "\n",
    "ensure_path_exists('data/', True)\n",
    "ensure_path_exists('clean/', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b83af8-57cf-4743-b03b-e04452200466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/citlalitrigos/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Downloaded file  CC-EST2020-ALLDATA6.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/asrh/CC-EST2020-ALLDATA6.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-01.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-01.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-02.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-02.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-04.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-04.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-05.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-05.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-06.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-06.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-08.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-08.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-09.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-09.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-10.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-10.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-11.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-11.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-12.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-12.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-13.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-13.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-15.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-15.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-16.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-16.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-17.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-17.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-18.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-18.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-19.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-19.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-20.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-20.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-21.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-21.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-22.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-22.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-23.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-23.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-24.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-24.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-25.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-25.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-26.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-26.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-27.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-27.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-28.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-28.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-29.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-29.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-30.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-30.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-31.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-31.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-32.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-32.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-33.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-33.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-34.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-34.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-35.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-35.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-36.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-36.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-37.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-37.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-38.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-38.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-39.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-39.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-40.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-40.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-41.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-41.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-42.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-42.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-44.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-44.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-45.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-45.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-46.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-46.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-47.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-47.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-48.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-48.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-49.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-49.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-50.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-50.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-51.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-51.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-53.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-53.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-54.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-54.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-55.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-55.csv\n",
      "<Response [200]>\n",
      "Downloaded file  cc-est2009-alldata-56.csv from  https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/cc-est2009-alldata-56.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "def get_soup(URL):\n",
    "    return bs(requests.get(URL).text, 'html.parser')\n",
    "\n",
    "def download_files(URL, desired_file_names, download_folder):\n",
    "    \"\"\"Downloads the given desired_file_names from given URL to given download_folder location\"\"\"\n",
    "    for link in get_soup(URL).findAll(\"a\", attrs={'href': re.compile(\".csv\")}):\n",
    "        file_link = link.get('href')\n",
    "        if file_link in desired_file_names:\n",
    "    \n",
    "            with open(os.path.join(download_folder, link.text), 'wb') as file:\n",
    "                response = requests.get(URL + file_link)\n",
    "                print(response)\n",
    "                \n",
    "                file.write(response.content)\n",
    "                print(\"Downloaded file \", file_link, \"from \", URL + file_link)\n",
    "\n",
    "# # step 1: download 2010 - 2020 files [multiple files]\n",
    "URL_step1 = \"https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/counties/asrh/\"\n",
    "desired_file_names_step1 = ['CC-EST2020-ALLDATA6.csv']\n",
    "download_folder = 'data/'\n",
    "download_files(URL_step1, desired_file_names_step1, download_folder)\n",
    "\n",
    "\n",
    "# step 2: download 2003 - 2009 files [multiple files]\n",
    "desired_counties = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
    "\n",
    "def get_desired_file_names(counties):\n",
    "    desired_file_names = []\n",
    "    for county_num in counties:\n",
    "        desired_file_names.append(\"cc-est2009-alldata-\"+ str(county_num).zfill(2) + '.csv')\n",
    "    return desired_file_names\n",
    "\n",
    "URL_step2 = \"https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/asrh/\"\n",
    "desired_file_names = get_desired_file_names(desired_counties)\n",
    "download_folder = 'data/'\n",
    "\n",
    "download_files(URL_step2, desired_file_names, download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da52cf-2569-404d-a8ac-f7b90cdac0ff",
   "metadata": {},
   "source": [
    " ### Step 2a: Prepare data for years 2010-2020\n",
    "In this step we deal with years 2010-2020. Let's use the file  `data/CC-EST2020-ALLDATA6.csv`. In this file, we keep the columns with the following headings: SUMLEV (column a) STATE (b), COUNTY (c), STNAME (d), CTYNAME (e), YEAR (f), AGEGRP (h), and any column with the suffix “_FEMALE” in the header (there should be 27 columns with this in the header but double check).\n",
    " \n",
    "We also need to keep the following rows:\n",
    "for STATE values 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56 (these correspond to the state FIPS codes for the contiguous 48 states plus Hawaii, DC, and Alaska). All COUNTY levels for each state should be kept.\n",
    " \n",
    "For YEAR, the following values should be kept: 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, where they correspond to July 1st of each year in the data\n",
    "\n",
    "\n",
    "- 2010 -- 3\n",
    "- ...\n",
    "- 2020 -- 14 \n",
    " \n",
    "For AGEGRP, 4, 5, 6, 7, 8, 9, and 10 should be kept; these correspond to five year age intervals from 15-19 to 45-49.\n",
    " \n",
    "Save the file as `cc-2010-2020.csv` under folder `clean`. We should have this organization\n",
    "\n",
    "- parent_folder/\n",
    "    - get-census-data.ipynb\n",
    "    - data/\n",
    "        -  CC-EST2020-ALLDATA6.csv\n",
    "        -  cc-est2009-alldate-1.csv\n",
    "        -  ...\n",
    "        -  cc-est2009-alldate-56.csv\n",
    "    - clean/\n",
    "        -  cc-2010-2020.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3a0c9f-7e58-4dba-8851-838974a69344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_columns(df):\n",
    "    \"\"\"Keeps only columns 'SUMLEV', 'STATE', 'COUNTY', 'STNAME', 'CTYNAME', 'YEAR', 'AGEGRP', or those that include '_FEMALE'\n",
    "      Takes in df and returns df\n",
    "    \"\"\"\n",
    "    female_cols = [col for col in df.columns if '_FEMALE' in col]\n",
    "    desired_cols = female_cols + ['SUMLEV', 'STATE', 'COUNTY', 'STNAME', 'CTYNAME', 'YEAR', 'AGEGRP']\n",
    "    df = df[df.columns[df.columns.isin(desired_cols)]]\n",
    "    return df\n",
    "\n",
    "def clean_state_values(df):\n",
    "    \"\"\"Keeps only state rows  1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21,\n",
    "       22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, \n",
    "    45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56\n",
    "    Takes in df and returns modified df\n",
    "    \"\"\"\n",
    "    desired_states = [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
    "    return df[df.STATE.isin(desired_states)]\n",
    "\n",
    "def clean_year_values_1(df):\n",
    "    \"\"\"Keeps only year rows for 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14\n",
    "    Takes in df and returns modified df\n",
    "    \"\"\"\n",
    "    desired_years = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14]\n",
    "    return df[df.YEAR.isin(desired_years)]\n",
    "\n",
    "\n",
    "def clean_age_grp_values(df):\n",
    "    \"\"\"Keeps only age group values 4, 5, 6, 7, 8, 9, 10\n",
    "    Takes in df and returns modified df\n",
    "    \"\"\"\n",
    "    desired_age_grp = [4, 5, 6, 7, 8, 9, 10]\n",
    "    return df[df.AGEGRP.isin(desired_age_grp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720915da-56a0-4638-ab02-f4a7de816eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/b6c49kjx5_526vwl3431rgcc0000gn/T/ipykernel_15122/248841949.py:2: DtypeWarning: Columns (7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  step1df = pd.read_csv('data/CC-EST2020-ALLDATA6.csv', encoding = \"ISO-8859-1\")\n"
     ]
    }
   ],
   "source": [
    "# read in the desired file \n",
    "step1df = pd.read_csv('data/CC-EST2020-ALLDATA6.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# clean the data \n",
    "step1df = clean_columns(step1df)\n",
    "step1df = clean_state_values(step1df)\n",
    "step1df = clean_year_values_1(step1df)\n",
    "step1df = clean_age_grp_values(step1df)\n",
    "\n",
    "# save to directory clean/\n",
    "step1df.to_csv(\"clean/cc-2010-2020.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bba6c6b-be46-488d-8472-e424f14cb722",
   "metadata": {},
   "source": [
    "### Step 2b: Prepare data for years 2003-2009\n",
    "In this step we deal with years 2003-2009, using the files under `cc-est2009-alldate-#.csv` We first clean them by removing unneeded columns and rows before aggregating them together. This data is kept the exact same columns as in Step 2A.\n",
    " \n",
    "For YEAR, the following values should be kept: 5, 6, 7, 8, 9, 10, 11, 13, where they correspond to July 1st of each year in the data\n",
    "For AGEGRP, 4, 5, 6, 7, 8, 9, and 10 should be kept; these correspond to five year age intervals from 15-19 to 45-49.\n",
    "\n",
    " - 5 -- 2003\n",
    " - ...\n",
    " - 13 -- 2009 \n",
    "\n",
    "Save the file as you go as `cc-2003-2009.csv` under folder `clean`\n",
    "\n",
    "- parent_folder/\n",
    "    - get-census-data.ipynb\n",
    "    - data/\n",
    "        -  CC-EST2020-ALLDATA6.csv\n",
    "        -  cc-est2009-alldate-1.csv\n",
    "        -  ...\n",
    "        -  cc-est2009-alldate-56.csv\n",
    "    - clean/\n",
    "        -  cc-2010-2020.csv\n",
    "        -  cc-2003-2009.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6381cd4d-ce0e-48cd-a87c-5817826a34cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extended with  cc-est2009-alldata-05.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 7987\n",
      "extended with  cc-est2009-alldata-11.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 8036\n",
      "extended with  cc-est2009-alldata-10.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 8183\n",
      "extended with  cc-est2009-alldata-04.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 8918\n",
      "extended with  cc-est2009-alldata-38.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 11515\n",
      "extended with  cc-est2009-alldata-12.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 14798\n",
      "extended with  cc-est2009-alldata-06.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 17640\n",
      "extended with  cc-est2009-alldata-13.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 25431\n",
      "extended with  cc-est2009-alldata-17.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 30429\n",
      "extended with  cc-est2009-alldata-02.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 31850\n",
      "extended with  cc-est2009-alldata-16.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 34006\n",
      "extended with  cc-est2009-alldata-28.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 38024\n",
      "extended with  cc-est2009-alldata-29.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 43659\n",
      "extended with  cc-est2009-alldata-15.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 43904\n",
      "extended with  cc-est2009-alldata-01.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 47187\n",
      "extended with  cc-est2009-alldata-48.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 59633\n",
      "extended with  cc-est2009-alldata-49.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 61054\n",
      "extended with  cc-est2009-alldata-47.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 65709\n",
      "extended with  cc-est2009-alldata-53.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 67620\n",
      "extended with  cc-est2009-alldata-46.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 70854\n",
      "extended with  cc-est2009-alldata-50.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 71540\n",
      "extended with  cc-est2009-alldata-44.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 71785\n",
      "extended with  cc-est2009-alldata-45.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 74039\n",
      "extended with  cc-est2009-alldata-51.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 80605\n",
      "extended with  cc-est2009-alldata-55.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 84133\n",
      "extended with  cc-est2009-alldata-41.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 85897\n",
      "extended with  cc-est2009-alldata-40.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 89670\n",
      "extended with  cc-est2009-alldata-54.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 92365\n",
      "extended with  cc-est2009-alldata-42.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 95648\n",
      "extended with  cc-est2009-alldata-56.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 96775\n",
      "extended with  cc-est2009-alldata-18.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 101283\n",
      "extended with  cc-est2009-alldata-24.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 102459\n",
      "extended with  cc-est2009-alldata-30.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 105203\n",
      "extended with  cc-est2009-alldata-31.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 109760\n",
      "extended with  cc-est2009-alldata-25.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 110446\n",
      "extended with  cc-est2009-alldata-19.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 115297\n",
      "extended with  cc-est2009-alldata-33.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 115787\n",
      "extended with  cc-est2009-alldata-27.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 120050\n",
      "extended with  cc-est2009-alldata-26.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 124117\n",
      "extended with  cc-est2009-alldata-32.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 124950\n",
      "extended with  cc-est2009-alldata-36.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 127988\n",
      "extended with  cc-est2009-alldata-22.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 131124\n",
      "extended with  cc-est2009-alldata-23.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 131908\n",
      "extended with  cc-est2009-alldata-37.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 136808\n",
      "extended with  cc-est2009-alldata-21.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 142688\n",
      "extended with  cc-est2009-alldata-35.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 144305\n",
      "extended with  cc-est2009-alldata-09.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 144697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/b6c49kjx5_526vwl3431rgcc0000gn/T/ipykernel_15122/2782817334.py:21: DtypeWarning: Columns (7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframe = pd.read_csv('data/'+file, encoding = \"ISO-8859-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extended with  cc-est2009-alldata-08.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 147833\n",
      "extended with  cc-est2009-alldata-34.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 148862\n",
      "extended with  cc-est2009-alldata-20.csv\n",
      "issue in adding dfs\n",
      "Number of rows in clean/cc-2003-2009.csv: 154007\n"
     ]
    }
   ],
   "source": [
    "# the only different cleaning is of the year values \n",
    "\n",
    "def clean_year_values_2(df):\n",
    "    \"\"\"Keeps only year rows for 5, 6, 7, 8, 9, 10, 11, 13\n",
    "    Takes in df and returns modified df\"\"\"\n",
    "    desired_years = [5, 6, 7, 8, 9, 10, 11, 13]\n",
    "    return df[df.YEAR.isin(desired_years)]\n",
    "    \n",
    "# get the file names we want from the data folder \n",
    "file_names = list(os.listdir('data/'))\n",
    "file_names = [name for name in file_names if \"cc-est2009-alldata-\"  in name]\n",
    "\n",
    "length_combined_so_far = 0\n",
    "\n",
    "# clean in case we already have this file\n",
    "if os.path.exists(\"clean/cc-2003-2009.csv\"):\n",
    "    os.remove(\"clean/cc-2003-2009.csv\")\n",
    "\n",
    "# for each of those files\n",
    "for file in file_names:\n",
    "    dataframe = pd.read_csv('data/'+file, encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    # clean the data \n",
    "    dataframe = clean_columns(dataframe)\n",
    "    dataframe = clean_state_values(dataframe)\n",
    "    dataframe = clean_year_values_2(dataframe)\n",
    "    dataframe = clean_age_grp_values(dataframe)\n",
    "\n",
    "    # save to directory clean/\n",
    "    if os.path.exists(\"clean/cc-2003-2009.csv\"):\n",
    "        extended_dfs = pd.concat([pd.read_csv(\"clean/cc-2003-2009.csv\"), dataframe])\n",
    "        extended_dfs.to_csv(\"clean/cc-2003-2009.csv\", index=False)\n",
    "        print(\"extended with \", file)\n",
    "        \n",
    "        # check that the csv is growing \n",
    "        combined_length = dataframe.shape[1] + length_combined_so_far\n",
    "        length_combined_so_far += dataframe.shape[0]\n",
    "        if length_combined_so_far!= combined_length: \n",
    "            print(\"issue in adding dfs\")\n",
    "        print(\"Number of rows in clean/cc-2003-2009.csv:\", length_combined_so_far) \n",
    "    else: \n",
    "        dataframe.to_csv(\"clean/cc-2003-2009.csv\", index=False)\n",
    "        length_combined_so_far = dataframe.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8263f-e3ee-41db-8bbc-607c46b32f36",
   "metadata": {},
   "source": [
    "### Step 3: Merge the files  \n",
    "Merge files `cc-2010-2020.csv` and `cc-2003-2009.csv` under folder `clean/` from step 2 and 3 into one final output file `cc-2003-2020-all-data.csv` under `clean`, to get: \n",
    "\n",
    "- parent_folder/\n",
    "    - get-census-data.ipynb\n",
    "    - data/\n",
    "        -  CC-EST2020-ALLDATA6.csv\n",
    "        -  cc-est2009-alldate-1.csv\n",
    "        -  ...\n",
    "        -  cc-est2009-alldate-56.csv\n",
    "    - clean/\n",
    "        -  cc-2010-2020.csv\n",
    "        -  cc-2003-2009.csv\n",
    "        -  cc-2003-2020.csv # this is the final file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5a6a1a-bd77-4b83-b8d0-6d484db695cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original year values\n",
      "2003-2009 dataframe:  [ 5  6  7  8  9 10 11]\n",
      "2010-2013 dataframe:  [ 3  4  5  6  7  8  9 10 11 12 14]\n",
      "updated year values\n",
      "2003-2009 dataframe:  [2003 2004 2005 2006 2007 2008 2009]\n",
      "2010-2013 dataframe:  [2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020]\n"
     ]
    }
   ],
   "source": [
    "# first we fix the years \n",
    "# get the data \n",
    "early_df = pd.read_csv(\"clean/cc-2003-2009.csv\")\n",
    "late_df = pd.read_csv(\"clean/cc-2010-2020.csv\")\n",
    "\n",
    "# get the original values for the years \n",
    "print(\"original year values\")\n",
    "print(\"2003-2009 dataframe: \",early_df.YEAR.unique())\n",
    "print(\"2010-2013 dataframe: \",late_df.YEAR.unique())\n",
    "\n",
    "# change the years in the 2003-2009 data from [ 5  6  7  8  9 10 11] to [2003 ... 2009]\n",
    "olderdict = {\n",
    "    5: 2003,\n",
    "    6: 2004,\n",
    "    7: 2005,\n",
    "    8: 2006, \n",
    "    9: 2007, \n",
    "    10: 2008, \n",
    "    11: 2009\n",
    "}\n",
    "# replace the values \n",
    "early_df = early_df.replace({\"YEAR\": olderdict})\n",
    "\n",
    "# change the years in the 2010+ data from [ 3  4  5  6  7  8  9 10 11 12 14] to [2010 ... 2020]\n",
    "newerdict = {\n",
    "    3: 2010, \n",
    "    4: 2011, \n",
    "    5: 2012, \n",
    "    6: 2013, \n",
    "    7: 2014, \n",
    "    8: 2015, \n",
    "    9: 2016, \n",
    "    10: 2017, \n",
    "    11: 2018, \n",
    "    12: 2019, # we skip 13 \n",
    "    14: 2020 \n",
    "}\n",
    "\n",
    "# replace the values \n",
    "late_df = late_df.replace({\"YEAR\": newerdict})\n",
    "\n",
    "\n",
    "print(\"updated year values\")\n",
    "print(\"2003-2009 dataframe: \",early_df.YEAR.unique())\n",
    "print(\"2010-2013 dataframe: \",late_df.YEAR.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9f0e4b-6dbd-4ce9-b5e1-6d23e8d4ba58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of clean/cc-2003-2009.csv: 154007\n",
      "Length of clean/cc-2010-2020.csv: 242011\n",
      "Length of clean/cc-2003-2020.csv: 396018\n"
     ]
    }
   ],
   "source": [
    "combined_dfs = pd.concat([early_df, late_df])\n",
    "combined_dfs.to_csv(\"clean/cc-2003-2020.csv\", index=False)\n",
    "\n",
    "\n",
    "print(f\"Length of clean/cc-2003-2009.csv: {early_df.shape[0]}\")\n",
    "print(f\"Length of clean/cc-2010-2020.csv: {late_df.shape[0]}\")\n",
    "print(f\"Length of clean/cc-2003-2020.csv: {combined_dfs.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbb47f79-3574-44b6-805d-bb5b5a5b52b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013,\n",
       "       2014, 2015, 2016, 2017, 2018, 2019, 2020])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dfs.YEAR.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
